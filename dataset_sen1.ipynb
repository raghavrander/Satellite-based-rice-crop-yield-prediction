{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c8e2ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7ed950",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user ipyleaflet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a21dd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyleaflet\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfe7ba3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Science\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43959d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pystac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875468e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pystac_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ffdaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user odc-stac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88398e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install planetary_computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e6e9155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Planetary Computer Tools\n",
    "import pystac\n",
    "import pystac_client\n",
    "import odc\n",
    "from pystac_client import Client\n",
    "from pystac.extensions.eo import EOExtension as eo\n",
    "from odc.stac import stac_load\n",
    "import planetary_computer as pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a435da85",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4b0de9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import rich.table\n",
    "from itertools import cycle\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dda14411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyleaflet\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pystac\n",
    "import pystac_client\n",
    "import planetary_computer\n",
    "import requests\n",
    "import rich.table\n",
    "\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc404ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  collectionDate    A-q102_state A-q103_district A-q104_subDistrict  \\\n",
      "0       19-02-20  Andhra Pradesh       Anantapur            Atmakur   \n",
      "1       19-02-20  Andhra Pradesh       Anantapur            Atmakur   \n",
      "2       19-02-20  Andhra Pradesh       Anantapur            Atmakur   \n",
      "3       19-02-20  Andhra Pradesh       Anantapur            Atmakur   \n",
      "4       19-02-20  Andhra Pradesh       Anantapur            Atmakur   \n",
      "\n",
      "  A-q105_village A-q111_fGender  A-q112_fEdu A-q114_socialCategory  \\\n",
      "0  Y. Kothapalli           male      primary               General   \n",
      "1  Y. Kothapalli           male  noSchooling               General   \n",
      "2   Singhampalli           male      primary                   OBC   \n",
      "3   Sunghampalli           male      primary                   OBC   \n",
      "4    Singampalli           male      primary                   OBC   \n",
      "\n",
      "  A-q116_crop A-q117_season  ... M-q704_agIncomeShare  M-q705_cropShareAg  \\\n",
      "0        Rice        Kharif  ...                 15.0                20.0   \n",
      "1        Rice        Kharif  ...                 15.0                 5.0   \n",
      "2        Rice        Kharif  ...                 20.0                15.0   \n",
      "3        Rice        Kharif  ...                 10.0                15.0   \n",
      "4        Rice        Kharif  ...                 10.0                15.0   \n",
      "\n",
      "   M-q706_cropSP  M-q707_cropAvgSP  M-q708_marketDistance  O-q801_newMgmtUse  \\\n",
      "0         3500.0               NaN                   35.0                NaN   \n",
      "1         3500.0               NaN                   35.0                NaN   \n",
      "2         3500.0               NaN                   35.0                NaN   \n",
      "3         3500.0               NaN                   35.0                NaN   \n",
      "4         3500.0               NaN                   35.0                NaN   \n",
      "\n",
      "  Latitude Longitude O-largestPlotGPS-Altitude O-largestPlotGPS-Accuracy  \n",
      "0   14.670    77.389                346.883606                  4.342759  \n",
      "1   14.670    77.390                378.864624                  4.732177  \n",
      "2   14.695    77.403                321.666626                  7.356012  \n",
      "3   14.694    77.403                333.353760                  4.488559  \n",
      "4   14.695    77.404                330.737549                  4.712837  \n",
      "\n",
      "[5 rows x 218 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read the CSV file\n",
    "df = pd.read_csv('C:/Users/Admin/Desktop/CE778/project/CSISA_IND_LDS_Rice_2018_Data.csv')\n",
    "\n",
    "# print the contents of the CSV file\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b54cb70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.settings.set_subscription_key('****************************')\n",
    "#get your subscription key from Microsoft Planetary Hub API and enter it here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0ea4e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=planetary_computer.sign_inplace,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bd7a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST EXAMPLE\n",
    "bbox = [77.389, 14.67, 77.39, 14.68]\n",
    "search = catalog.search(\n",
    "    collections=[\"sentinel-1-rtc\"], bbox=bbox, datetime=\"2017-01-01/2019-12-31\"\n",
    ")\n",
    "items = search.item_collection()\n",
    "print(f\"Found {len(items)} items\")\n",
    "item = items[0]\n",
    "# Iterate through each item and print its date\n",
    "for item in items:\n",
    "    date = item.properties[\"datetime\"]\n",
    "    print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bac935",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url=item.assets[\"rendered_preview\"].href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ac5e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# from datetime import datetime\n",
    "# from collections import defaultdict\n",
    "# def get_vv_vh(longitude, latitude, csv_file):\n",
    "    \n",
    "#     assests = ['vh','vv']\n",
    "#     str_latitude = str(latitude)\n",
    "#     found_start_date = False\n",
    "\n",
    "#     with open(csv_file, 'r') as file:\n",
    "#         reader = csv.DictReader(file)\n",
    "#         for row in reader:\n",
    "# #             if (row['Latitude'] == str_latitude) & (row['A-q117_season'] == season):\n",
    "# #                     start_date = row['D-q406_prevCropHarvest']\n",
    "# #                     found_start_date = True\n",
    "# #                     #print(start_date)\n",
    "    \n",
    "# #         date_obj = datetime.strptime(date, \"%d-%m-%y\")\n",
    "# #         new_date_csv = date_obj.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# #         if found_start_date:\n",
    "# #             print(\"Found\")\n",
    "# #             start_date_obj = datetime.strptime(start_date, \"%d-%m-%y\")\n",
    "# #             new_start_date_csv = start_date_obj.strftime(\"%Y-%m-%d\")\n",
    "# #             if new_start_date_csv > \"2018-07-01\":\n",
    "# #                 print(\"bigger\")\n",
    "# #                 datetime1 = new_date_csv + \"/\" + new_start_date_csv\n",
    "# #                 print(datetime1)\n",
    "\n",
    "# #             else:\n",
    "# #                 print(\"smaller\")\n",
    "# #                 datetime1 = new_date_csv + \"/\" + \"2018-07-01\"\n",
    "# #                 print(datetime1)\n",
    "\n",
    "# #         else:\n",
    "# #             print(\"not\")\n",
    "# #             datetime1 = \"2018-07-01\" + \"/\" + new_date_csv\n",
    "# #             print(datetime1)\n",
    "\n",
    "    \n",
    "# #     if season == 'Rabi':\n",
    "# #         date_obj = datetime.strptime(date, \"%d-%m-%y\")\n",
    "# #         new_date_csv = date_obj.strftime(\"%Y-%m-%d\")\n",
    "# #         datetime1 = \"2017-11-01\" +\"/\" + new_date_csv\n",
    "# #         print(datetime1)\n",
    "#             start_date = datetime.strptime(row['D-q415_seedingSowingTransDate'], \"%d-%m-%y\").strftime(\"%Y-%m-%d\")\n",
    "\n",
    "#             end_date = datetime.strptime(row['L-q601_harvestDate'], \"%d-%m-%y\").strftime(\"%Y-%m-%d\")\n",
    "#             datetime1 = start_date+\"/\"+end_date\n",
    "    \n",
    "#     bbox = [longitude, latitude, longitude, latitude]\n",
    "#     search = catalog.search(\n",
    "#         collections=[\"sentinel-1-rtc\"], bbox=bbox, datetime=datetime1\n",
    "#     )\n",
    "\n",
    "#     items = search.item_collection()\n",
    "#     print(f\"Found {len(items)} items\")\n",
    "#     item = items[1]\n",
    "#     print(item)\n",
    "#     # Access the datetime for each item\n",
    "#     #for item in items:\n",
    "#     #   print(f\"Item ID: {item.id}, Datetime: {item.datetime}\")\n",
    "#     import stackstac\n",
    "\n",
    "# #     ds = stackstac.stack(items[0], bounds_latlon=bbox, epsg=32630, resolution=100)\n",
    "# #     #ds\n",
    "\n",
    "#     vv_list = []\n",
    "#     vh_list = []\n",
    "#     row_indices_no_values = []\n",
    "#     bands_of_interest = ['vh', 'vv']\n",
    "#     for item in items:\n",
    "#         data = stac_load([item], bands=bands_of_interest, patch_url=pc.sign, bbox=bbox).isel(time=0)\n",
    "#         if (data['vh'].values[0][0] !=-32768.0 and data['vv'].values[0][0]!=-32768.0):\n",
    "#             vv_list.append(np.median(data[\"vv\"].astype(\"float64\")))\n",
    "#             vh_list.append(np.median(data[\"vh\"].astype(\"float64\")))\n",
    "    \n",
    "#     return vv_list, vh_list\n",
    "df = df.drop_duplicates()\n",
    "i\n",
    "# Dropping rows where 'L-q601_harvestDate' column has entry \"00-01-00\"\n",
    "df = df[df['L-q601_harvestDate'] != \"00-01-00\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe7595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dropping rows where 'L-q601_harvestDate' column has entry \"00-01-00\"\n",
    "df = df[df['L-q601_harvestDate'] != \"00-01-00\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcd96801",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Save the sampled DataFrame to a new file, for example, CSV\n",
    "sampled_df=pd.read_csv('sampled_data_rice.csv')  # Change 'sampled_data.csv' to your desired file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1116cafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0531e3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min_vh_list = []\n",
    "min_vv_list = []\n",
    "max_vh_list = []\n",
    "max_vv_list = []\n",
    "range_vh_list = []\n",
    "range_vv_list = []\n",
    "mean_vh_list = []\n",
    "mean_vv_list = []\n",
    "std_vh_list = []\n",
    "std_vv_list = []\n",
    "ratio_vv_vh_list = []\n",
    "rvi_list = []\n",
    "latitude_list = []\n",
    "longitude_list = []\n",
    "sowing=[]\n",
    "harvesting=[]\n",
    "\n",
    "for index, row in sampled_df.iloc[800:].iterrows():\n",
    "    # Extract values from each row\n",
    "    longitude = row['Longitude']\n",
    "    latitude = row['Latitude']\n",
    "    start = row['D-q415_seedingSowingTransDate']\n",
    "    end = row['L-q601_harvestDate']\n",
    "    print(start)\n",
    "    print(end)\n",
    "    start_date = datetime.strptime(row['D-q415_seedingSowingTransDate'], \"%d-%m-%y\").strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    end_date = datetime.strptime(row['L-q601_harvestDate'], \"%d-%m-%y\").strftime(\"%Y-%m-%d\")\n",
    "    datetime1 = start_date+\"/\"+end_date\n",
    "    print(datetime1)\n",
    "    bbox = [longitude, latitude, longitude, latitude]\n",
    "    search = catalog.search(\n",
    "        collections=[\"sentinel-1-rtc\"], bbox=bbox, datetime=datetime1\n",
    "    )\n",
    "\n",
    "    items = search.item_collection()\n",
    "    if not items or len(items) == 1:\n",
    "        continue  # Skip to the next iteration if item collection is empty or contains only one item\n",
    "    print(f\"Found {len(items)} items\")\n",
    "    item = items[1]\n",
    "    print(item)\n",
    "    # Access the datetime for each item\n",
    "    #for item in items:\n",
    "    #   print(f\"Item ID: {item.id}, Datetime: {item.datetime}\")\n",
    "    import stackstac\n",
    "\n",
    "#     ds = stackstac.stack(items[0], bounds_latlon=bbox, epsg=32630, resolution=100)\n",
    "#     #ds\n",
    "\n",
    "    vv_list = []\n",
    "    vh_list = []\n",
    "    row_indices_no_values = []\n",
    "    bands_of_interest = ['vh', 'vv']\n",
    "    for item in items:\n",
    "        data = stac_load([item], bands=bands_of_interest, patch_url=pc.sign, bbox=bbox).isel(time=0)\n",
    "        if (data['vh'].values[0][0] !=-32768.0 and data['vv'].values[0][0]!=-32768.0):\n",
    "            vv_list.append(np.median(data[\"vv\"].astype(\"float64\")))\n",
    "            vh_list.append(np.median(data[\"vh\"].astype(\"float64\")))\n",
    "    \n",
    "    # Call get_vv_vh function with extracted values\n",
    "#     vv_list, vh_list = get_vv_vh(longitude, latitude, 'C:/Users/Admin/Desktop/CE778/project/CSISA_IND_LDS_Rice_2018_Data.csv')\n",
    "    \n",
    "    # Calculate parameters\n",
    "    if vv_list and vh_list:\n",
    "        vv_values = np.array(vv_list)\n",
    "        vh_values = np.array(vh_list)\n",
    "        min_vh = np.min(vh_values)\n",
    "        min_vv = np.min(vv_values)\n",
    "        max_vh = np.max(vh_values)\n",
    "        max_vv = np.max(vv_values)\n",
    "        range_vh = np.ptp(vh_values)\n",
    "        range_vv = np.ptp(vv_values)\n",
    "        mean_vh = np.mean(vh_values)\n",
    "        mean_vv = np.mean(vv_values)\n",
    "        std_vh = np.std(vh_values)\n",
    "        std_vv = np.std(vv_values)\n",
    "        ratio_vv_vh = mean_vv / mean_vh\n",
    "        rvi = (mean_vv + mean_vh) / (mean_vv - mean_vh)\n",
    "\n",
    "        # Append calculated parameters to respective lists\n",
    "        latitude_list.append(latitude)\n",
    "        longitude_list.append(longitude)\n",
    "        min_vh_list.append(min_vh)\n",
    "        min_vv_list.append(min_vv)\n",
    "        max_vh_list.append(max_vh)\n",
    "        max_vv_list.append(max_vv)\n",
    "        range_vh_list.append(range_vh)\n",
    "        range_vv_list.append(range_vv)\n",
    "        mean_vh_list.append(mean_vh)\n",
    "        mean_vv_list.append(mean_vv)\n",
    "        std_vh_list.append(std_vh)\n",
    "        std_vv_list.append(std_vv)\n",
    "        ratio_vv_vh_list.append(ratio_vv_vh)\n",
    "        rvi_list.append(rvi)\n",
    "        sowing.append(start)\n",
    "        harvesting.append(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876dd48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vv_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0a8471",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_lists = [sowing,harvesting,latitude_list,longitude_list,min_vh_list, min_vv_list, max_vh_list, max_vv_list, range_vh_list, range_vv_list,\n",
    "                   mean_vh_list, mean_vv_list, std_vh_list, std_vv_list, ratio_vv_vh_list, rvi_list]\n",
    "import csv\n",
    "# Save the lists as columns in a CSV file\n",
    "with open('C:/Users/Admin/Desktop/CE778/project/sentinel1_rtc_new_2000_3.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the column headers\n",
    "    writer.writerow(['Sowing','Harvesting','Latitude','Longitude','min_vh', 'min_vv', 'max_vh', 'max_vv', 'range_vh', 'range_vv',\n",
    "                     'mean_vh', 'mean_vv', 'std_vh', 'std_vv', 'ratio_vv_vh', 'rvi'])\n",
    "\n",
    "    # Write the data rows\n",
    "    for row in zip(*parameter_lists):\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dfe8b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b1feba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
